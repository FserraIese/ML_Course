{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression\n",
    "\n",
    "## Miguel Ángel Canela, IESE Business School\n",
    "\n",
    "******\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In machine learning, the term **regression** applies to the prediction of a numeric target. Regression models are not necessarily related to a mathematical equation, as in statistical analysis, although an equation is the first idea that comes to our mind when we think about \"predicting\". When the equation is linear, as in \n",
    "\n",
    "$$Y = b_0 + b_1X_1 + b_2X_2 + \\cdots + b_kX_k,$$\n",
    "\n",
    "we have **linear regression**, which is the subject of this note. The predictions of a linear regression model can typically be improved by more sophisticated techniques, but most analysts start there, because it helps them to understand the data. \n",
    "\n",
    "An alternative approach would be based **regression trees** or, better, in a combination of regression trees. These models will be discussed later in this course. \n",
    "\n",
    "### Evaluation of a linear regression model\n",
    "\n",
    "In general, regression models are evaluated through their **prediction errors**. The basic schema is\n",
    "\n",
    "$$\\hbox{Prediction error} = \\hbox{Actual value} - \\hbox{Predicted value}.$$\n",
    "\n",
    "In a linear regression context, prediction errors are called **residuals**. In the standard approach to linear regression, the regression coefficients are calculated so that the sum of the squared residuals is minimum. This is called the **least squares method**. The errors of a linear equation obtained by means of the least squares method have an important property, that their sum is zero, which is no longer true in other regression models.\n",
    "\n",
    "Statisticians look at the **residual sum of squares** for evidence of good fit between the model and the data. The **$R$-squared statistic** is a standardized measure which operationalizes this. More specifically, they take advantage of the formula\n",
    "\n",
    "$${\\rm var}\\big({\\rm Actual\\ values}\\big) =\n",
    "{\\rm var}\\big({\\rm Predicted\\ values}\\big) +\n",
    "{\\rm var}\\big({\\rm Prediction\\ error}\\big)$$\n",
    "\n",
    "to evaluate the model through the **proportion of variance explained**,\n",
    "\n",
    "$$R^2={{\\rm var}\\big({\\rm Predicted\\ values}\\big)\\over\n",
    "  {\\rm var}\\big({\\rm Actual\\ values}\\big)}\\,.$$\n",
    "\n",
    "It turns out that the square root of $R$-squared coincides with the **correlation** between the actual and the predicted values, called the **multiple correlation** in statistics textbooks. Although this stops being true for other regression methods, this correlation is still the simplest approach to the evaluation of a regression model.\n",
    "\n",
    "In a machine learning library like scikit-learn, there are several of methods for evaluating a regression model, which are not the same as those for evaluating classification models. You will find this in the module `sklearn.metrics`. The top popular ones are `mean_squared_error`, which is (almost) equal to the variance of the predicted error, and the `r2_score`, which is the $R$-squared of statisticians.\n",
    "\n",
    "### References\n",
    "\n",
    "1. A Géron (2017), *Hands-On Machine Learning with Scikit-Learn and TensorFlow --- Concepts, Tools, and Techniques to Build Intelligent Systems*, O'Reilly.\n",
    "\n",
    "2. F Provost & T Fawcett (2013), *Data Science for Business --- What You Need to Know About Data Mining and Data-Analytic Thinking*, O'Reilly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
