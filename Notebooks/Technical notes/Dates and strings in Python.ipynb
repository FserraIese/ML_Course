{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dates and strings in Python\n",
    "\n",
    "## Miguel Ángel Canela, IESE Business School\n",
    "\n",
    "******\n",
    "\n",
    "### Date and datetime\n",
    "\n",
    "In computer environments, there are typically two data types for time, called date and datetime. In **type date** we can store dates, that is, year, month and day. Most software applications for data management and analysis can deal with different date formats. The default format for dates in most languages, including Python, is `yyyy-mm-dd`. I advise you to use only this everywhere. Under the hood, a variable of type `date` is just a number, the number of days since a time origin, which is, typically, 1970-01-01 (in particular in Python). \n",
    "\n",
    "In data of **type datetime**, we store the same as in type date, plus hour, minute and second. The preferred format is `yyyy-mm-dd hh:mm:ss`. Sometimes, an indication of the time zone is added at the end, as we will see below. Examples are CET (Central European Time), CEST (Central European Summer Time), GMT (Greenwich Mean Time) and UTC (Coordinated Universal Time). Datetime is also called **timestamp**. Under the hood, datetime is the number of seconds since the time origin.\n",
    "\n",
    "Data of type datetime can be managed in many ways in Python. The package `datetime` is recommended if you want to the deal with times one by one, not within a data frame. The functions `datetime.date` and `datetime.datetime` can be used to create dates and datetimes. The dates are just datetimes in disguise, that is, the date `1954-04-30` is the same as the datetime `1954-04-30 00:00:00`.\n",
    "\n",
    "The old date and datetime types became obsolete when the **type datetime64** was introduced in Numpy. In this data type, times are recorded down to the nanosecond,\n",
    "$$1\\ {\\rm nanosecond} = 10^{-9}\\ {\\rm seconds}.$$ \n",
    "\n",
    "So a datetime64 is just the number of nanoseconds since the time origin. Pandas inherits this from Numpy. My presentation here is very brief, and restricted to the management of times in Pandas data structures. So, I start by creating a series which contains a time as a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1954-04-30 05:00:00\n",
       "dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "time1 = pd.Series('1954-04-30 05:00:00')\n",
    "time1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the function `astype`, which is typically used for type conversions in Pandas structures, we can put this as a datetime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   1954-04-30 05:00:00\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time2 = time1.astype('datetime64')\n",
    "time2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expression 'ns' between the square brackets means nanoseconds. We can go back to the original string type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1954-04-30 05:00:00\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time2.astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I said before, `time2` is just a number of nanoseconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -494622000000000000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time3 = time2.astype('int64')\n",
    "time3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   1954-04-30 05:00:00\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time3.astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion of numbers into times can also be performed at other levels. The following two examples illustrate this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   1997-05-19\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_days = pd.Series(10**4)\n",
    "num_days.astype('datetime64[D]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2001-09-09 01:46:40\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_secs = pd.Series(10**9)\n",
    "num_secs.astype('datetime64[s]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attribute `apply` is used to apply a function term by term to a column of a data frame. `apply` is typically used in combination with a lambda expression. Using `apply` and an appropriate lambda expression, we can extract from a datetime series any information that can be extracted from a datatime variable. For instance, we can see that April 30, 1954 was a Monday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    <built-in method weekday of Timestamp object a...\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time2.apply(lambda x: x.weekday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*. For the function `weekday`, Monday is 0 and Sunday is 6. With `isoweekday`, Monday is 1 and Sunday is 7.\n",
    "\n",
    "### String data\n",
    "\n",
    "Python provides a collection of methods for manipulating string variables. This includes not only sequences of **alphanumeric characters**, but also **white space** and **punctuation**. Beware that the **empty string** (`''`) is not the same as `nan`. It is a string of length zero.\n",
    "\n",
    "We also have in Pandas a collection of string functions. They are mostly those of plain Python, but they are vectorized in Pandas and use the syntax we are familiar with. So, if `df` is a data frame and `var` is one of the columns of `df`, we input `df['var'].str.func` to obtain a Pandas series whose terms will result from applying the function `func` to the series `df['var']`. I present next a brief review of some useful Pandas string functions.\n",
    "\n",
    "* With the function `str.len`, we **get the length of every element of a string series**. Note, in the following example, how the empty string and the missing value are dealt with. Also, note that the series containing the lengths has been coerced by Python to type float to cope with the `nan` value (the length has int type when all the strings have length)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Donald Trump\n",
       "1    Bill Clinton\n",
       "2                \n",
       "3             NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "presidents = pd.Series(['Donald Trump', 'Bill Clinton',\n",
    "    '', np.nan])\n",
    "presidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12.0\n",
       "1    12.0\n",
       "2     0.0\n",
       "3     NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "presidents.str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Substrings** can be extracted from a string variable just as we extract elements from a list. The same works for a string series (adding `str`). This can be useful to manage dates, as shown in the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2016'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'2016-10-06'[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2016\n",
       "1    2015\n",
       "2    2016\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = pd.Series(['2016-10-06', '2015-08-19', '2016-01-30'])\n",
    "dates.str[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Strings are joined** just as lists, with the plus sign (`+`) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Leonard'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Leo' + 'nard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Marvin Gaye\n",
       "1    Leonard Cohen\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstnames = pd.Series(['Marvin', 'Leonard'])\n",
    "secondnames = pd.Series(['Gaye', 'Cohen'])\n",
    "firstnames + ' ' + secondnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Many methods of string data analysis are based on counting the occurrences of selected terms. Counting is typically preceded by **conversion to lowercase**, performed with the function `str.lower`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       pablo\n",
       "1    liudmila\n",
       "2    nana yaa\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students = pd.Series(['Pablo', 'Liudmila', 'Nana Yaa'])\n",
    "students.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `str.contains` is used to **detect the presence or absence of a pattern in a string**. It returns a Boolean series indicating, term by term, whether the pattern occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students.str.contains(pat='an')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The function`str.findall` is used to **extract matching patterns from a string**. It produces, for each term of the series, a list containing all the occurrences of the pattern. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             [a]\n",
       "1             [a]\n",
       "2    [a, a, a, a]\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students.str.findall(pat='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* With the function `str.replace`, we can **replace matched patterns in a string**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Pablo\n",
       "1    Liudmila\n",
       "2    Nana-Yaa\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students.str.replace(pat=' ', repl='-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not that, while the third argument of `str.replace` (the replacement) has to be a single string, the second argument (the pattern) can be multiple. In the preceding example, we replaced a single white space by a dash. Now, to replace either white space or the letter 'o', we set as the pattern to replace the regular expression 'o| '. Note that, in Python (as in many other computer environments), the vertical bar means 'OR'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Pabl-\n",
       "1    Liudmila\n",
       "2    Nana-Yaa\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " students.str.replace(pat='o| ', repl='-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The function `str.split` **splits up a string into pieces**. This is one way to transform a string into a **bag of words**, that is, a list whose terms are the words contained in the string. For every term of a string series, the function returns the corresponding bag of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [Correlation, is, not, causation]\n",
       "1    [Flattery, is, the, food, of, fools]\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sayings = pd.Series(['Correlation is not causation',\n",
    "    'Flattery is the food of fools'])\n",
    "sayings.str.split(pat=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular expressions\n",
    "\n",
    "Some of the transformations performed by the methods described in the preceding section are dramatically simplified by using **regular expressions**. A regular expression is a pattern which describes a set of strings. Regular expressions are a whole chapter of programming, with entire books, such as Friedl (2007), devoted to them. If you are interested, you may also try the website `regexr.com`, which makes fun of learning regular expressions.\n",
    "\n",
    "Regular expressions can be used in many computer environments, but they are not exactly the same for different languages. Nevertheless, the basic ones are universal. Among them, **character classes** are the simplest case. They are built by enclosing a collection of characters within square brackets. The square brackets indicate *any* of the characters enclosed. For instance, `[0-9]` stands for any digit, and `[A-Z]` for any capital letter. \n",
    "\n",
    "I show how this works with some simple examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             I xxx xxxx xx 1954\n",
       "1    Mx xxxxx xx +34 932 534 200\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bio = pd.Series(['I was born in 1954',\n",
    "    'My phone is +34 932 534 200'])\n",
    "bio.str.replace(pat='[a-z]', repl='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             I was born in xxxx\n",
       "1    My phone is +xx xxx xxx xxx\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bio.str.replace(pat='[0-9]', repl='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Character classes get more powerful when complemented with **quantifiers**. For instance, followed by a plus sign (+), a character class indicates a sequence of any length. So, `[0-9]+` indicates any sequence of digits, therefore any number. We can also specify the minimum and maximum length of the sequence, as in the second example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             x x x x 1954\n",
       "1    x x x +34 932 534 200\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bio.str.replace(pat='[a-zA-Z]+', repl='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        I was born in xx\n",
       "1    My phone is +x x x x\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bio.str.replace(pat='[0-9]{1,3}', repl='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, a simple clean way of getting a bag of words is as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              [I, was, born, in, 1954]\n",
       "1    [My, phone, is, 34, 932, 534, 200]\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bio.str.findall(pat='[a-zA-Z0-9]+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special characters\n",
    "\n",
    "Text imported from PDF or HTML documents, or from devices like mobile phones, may contain **special characters** like the left/right quotation marks (‘, “, etc), or the three-dot character (…), which is better to control, to avoid confusion. To keep this note short, I do not develop this point here, but mind that, if you capture string data on your own, you will probably find some of that in your data. Even if the documents are expected to be in English, they can be contaminated by other languages: Han characters, German umlaut, Spanish eñe, etc.\n",
    "\n",
    "Another source of trouble is that these special symbols can be encoded by different computers or different text editors in different ways. The preferred **encoding** is **UTF-8**, which is the default encoding in Macintosh computers. Reading and writing files text files in R, the argument `fileEncoding` allows you to mange allows you to manage both UTF-8 and the alternative encoding **Latin-1**. The problem with Windows computers is that they use a third system, called **Windows-1252**, which is very close to Latin-1, but not exactly the same. I cannot say more, because this topic goes beyond my expertise, so I do not discuss encodings in this course. If you are interested, you may take a look at Korpela (2006).\n",
    "\n",
    "### References\n",
    "\n",
    "1. JEF Friedl (2007), *Mastering Regular Expressions*, O'Reilly.\n",
    "\n",
    "2. JK Korpela (2006), *Unicode Explained*, O'Reilly.\n",
    "\n",
    "3. J VanderPlas (2017), *Python Data Science Handbook*, O'Reilly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
