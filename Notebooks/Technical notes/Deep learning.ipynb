{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning\n",
    "\n",
    "## Miguel Ángel Canela, IESE Business School\n",
    "\n",
    "******\n",
    "\n",
    "###  What is deep learning?\n",
    "\n",
    "**Deep learning**, the current star of machine learning, is based on neural networks. The success of deep learning, not yet fully understood (at least by some of us), is attributed to the ability of creating improved **representations** of the input data by means of successive layers of features. A feature in one layer (which is a node in a neural network) is obtained as the result of applying an **activation function** to a linear combination of the features of the previous layer. The **weights** of these linear expressions are optimal, meaning that a **loss**, calculated as a function of the prediction errors, is minimum.\n",
    "\n",
    "Under this perspective, deep learning is a successful approach to **feature engineering**. Why is this needed? Because, in many cases, the available features do not provide an adequate representation of the data, so an algorithm which replaces the original features by a new set may be useful. At the price of oversimplifying a complex question, the following two examples may help to understand this:\n",
    "\n",
    "* A model for predicting the sale price of a house from features like the square footage of the plot and the house, the location, the number of bedrooms, the existence of a garage, etc. You will probably agree that these are, indeed, the features that determine the price, so they provide a good representation of the data, and a **shallow learning** algorithm, such as a random forest regressor, would be a good approach. No feature engineering is needed here.\n",
    "\n",
    "* A model for **image classification**. Here, the available features are related to a grid of pixels. But we do not classify an image based on specific pixel positions. Recognition is based on shapes and corners. A shape is a created by a collection of pixels, each of them close to the preceding one. And a corner is created by tho shapes intersecting in a specific way. So, we have the input layer of pixels, a first hidden layer of shapes providing a better representation, a second layer of corners providing an even better representation.\n",
    "\n",
    "The number of hidden layers in a neural network is called the **depth**. But, although deep learning is based on neural networks with more than one hidden layer, there is more in deep learning than additional layers. In the MLP model as we have seen it, every hidden node in a hidden layer is connected to all the nodes of the preceding layer and all the nodes of the following layer. In the deep learning context, these fully-connected layers are called **dense**. But there are other types of layers, as we see below, and the most glamorous applications of deep learning are based on networks which are not fully-connected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow and Keras\n",
    "\n",
    "The mathematics involved in the specification of the neural networks used in deep learning are written in terms of **tensors**. A tensor is the same as what we call array in NumPy. So, a 0D tensor is a scalar (a number), a 1D tensor is a vector, a 2D tensor is a matrix, etc. The operations with tensors and their properties are the object of **tensor algebra**, which is an extension of the matrix algebra which you may have met in undergraduate courses.\n",
    "\n",
    "You do not need to worry about the math technicalities, as far as you pay attention to the specification of the  **shape** of the input and output tensors in every layer of the network. Among the many attempts to implement the mathematics of the deep learning networks, including the tensors, the top popular one is **TensorFlow**, developed at Google Brain and released in 2015. The main competitor is PyTorch, released by Facebook. Recent news are that PyTorch is becoming the top choice in research (academic journals and conferences), although TensorFlow is still the indisputed leader in industry (job listings). \n",
    "\n",
    "**Keras** is a deep learning framework for Python (there is also a version for R), which provides a convenient way to define and train deep learning algorithms. Its documentation is available at `keras.io` (though Chollet's book is worth the price). Keras does not handle itself low-level operations such as tensor manipulation and differentiation. Instead, it relies on a specialized tensor library to do so. That library serves as the **backend engine** of Keras. Keras is organized in a modular way, so several different backend engines can be plugged seamlessly into Keras. Currently, the three existing backend implementations are the TensorFlow backend, the Theano backend, and the CNTK backend.\n",
    "\n",
    "The leading choice of deep learning aficionados, nowadays, seems to be the combination of TensorFlow (backend) and Keras (frontend). Pythonistas can have this combo in two ways. (a) using the `keras` package with the default backend, which is TensorFlow, so they do not have to specify the backend, or (b) using the module `keras` of the package `tensorflow`. For the first option, you can help yourself with Chollet (2017) or the Keras website. For the second option, use Géron (2017), or the TensorFlow API documentation site (`tensorflow.org/api_docs/python/tf`). The rest of this note refers to the first option, for which you only have to install Keras. Installing Keras, TensorFlow is installed on the fly. Just to give you an idea why Keras is popular, it has been said that the number of keystrokes needed to specify a deep learning model in Keras is one half of what was needed in old TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Keras script\n",
    "\n",
    "Let me suppose, to keep it short, that we wish to train a classification algorithm. For a first experience with Keras, you will have enough with modules `utils`, `models` and `layers`:\n",
    "\n",
    "    from keras import utils, models, layers\n",
    "\n",
    "To specify a classifier in Keras, the target vector has to be transformed into a matrix in which each column is a dummy associated to one of the target values. This can be done in many ways, using Pandas or scikit-learn. In Keras itself, it is done with the function `to_categorical`, from `utils`:\n",
    "\n",
    "    y = utils.to_categorical(y, dtype=int)\n",
    "\n",
    "The module `models` has two classes, `Sequential` and `Model`. The first one, in which we add layers in a sequential way with the method `add`, are enough for most of us. The other class, known as the **Functional API**, is used with more sophisticated architectures. We start initializing the class, with the default specification:\n",
    "\n",
    "    network = models.Sequential()\n",
    "\n",
    "The layers added are specified using classes from the module `layers`, such as `Dense` (if you only use these, you get just an MLP network), `Conv2D`, `MaxPooling`, `Flatten`, etc. For instance, an MLP model with one hidden layer of 32 nodes for the MNIST data would be specified as:\n",
    "\n",
    "    network.add(layers.Dense(32, activation='relu', input_shape=(784, )))\n",
    "    network.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "Once the network architecture is completely specified, the model is compiled, with the method `compile`:\n",
    "\n",
    "    network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "Finally, we apply the method `fit`, which is just a bit more complex than in scikit-learn:\n",
    "\n",
    "    network.fit(X, y, epochs=5, batch_size=64)\n",
    "    \n",
    "The **number of epochs** is typically low, to prevent overfitting. The default is `epochs=1`. The **batch size** is typically set as a power of 2, the default being 32, although 64 is more popular. Note that these defaults are different from those of scikit-learn.\n",
    "\n",
    "Eventually, you can add a `network.predict()` line, but you are already familiar with this, so I stop here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application to computer vision\n",
    "\n",
    "A **convolutional neural network** (CNN, or ConvNet) is a regularized version of a multilayer perceptron. By multilayer perceptron, we usually mean a fully-connected network, that is, one in which each neuron in one layer is connected to all neurons in the next layer. Fully-connectedness makes an MLP algorithm prone to overfitting data. \n",
    "\n",
    "On the other way, CNN's have low connectivity, and connections are selected according a design which takes advantage of the hierarchical pattern in the data and assemble complex patterns using smaller and simpler patterns. The fundamental difference between a dense layer and a **convolution layer** is that dense layers learn global patterns in their input feature space (e.g. for a MNIST digit, patterns involving all pixels), while convolution layers learn local patterns, i.e. patterns found in small 1D or 2D windows of the inputs. \n",
    "\n",
    "There are two subtypes of convolutional networks, 1D convolutional networks, used with sequence data (see next session) and 2D convolutional networks, used in image classification, and also in **recommendation systems** and **natural language processing** (NLP). In the CNN's used in image classification, convolutions operate over 3D tensors, called **feature maps**, with two spatial axes (`height` and `width`) as well as a `channels` axis. For a RGB image, the dimension of the `channels` axis would be 3, since the image has 3 color channels, red, green, and blue. For black and white pictures like the MNIST digits, it is just 1 (levels of gray).\n",
    "\n",
    "The convolution operation extracts patches from its input feature map, and applies the same transformation to all of these patches, producing an output feature map. This output feature map is still a 3D tensor: it still has a width and a height. Its depth can be arbitrary, since the output depth is a parameter of the layer, and the different channels in that depth axis no longer stand for specific colors like in an RGB input, rather they stand for what we call **filters**. The filters encode specific aspects of the input data. For instance, at a high level, a single filter could be encoding the concept \"presence of a face in the input\".\n",
    "\n",
    "Practitioners typically use two strategies for extracting more of their data:\n",
    "\n",
    "* **Transfer learning**. Instead of starting to train your model with random coefficients, you start with those of a model which has been pretrained with other data. Thre are many options for that among the classification algorithms that have been trained the **ImageNet** database (see `image-net.org`). \n",
    "\n",
    "* Expanding the training data with images obtained by transforming the original images. Typical transformations are: rotation with a random angle, random shift and zoom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application to sequence data\n",
    "\n",
    "The second area of success of deep learning is **sequence data**. This is a generic expression including text (sequences of words or characters), time series data, video and others. Although I do not have room here for this type of data, let me mention that the main types of networks used in this context are:\n",
    "\n",
    "* **1D convolutional networks**, with applications to machine translation, document classification and spelling correction.\n",
    "\n",
    "* **Recurrent neural networks** (RNN), with applications to handwritting and speech recognition, sentiment analysis, video classification, and time series data\n",
    "\n",
    "* Networks with **embedding** layers, with applications to recommendation systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "1. F Chollet (2017), *Deep Learning with Python*, Manning.\n",
    "\n",
    "2. F Chollet & JJ Allaire (2018), *Deep Learning with R*, Manning.\n",
    "\n",
    "3. A Géron (2017), *Hands-On Machine Learning with Scikit-Learn & TensorFlow*, O'Reilly.\n",
    "\n",
    "4. H He (2019), The state of machine learning frameworks in 2019, *The Gradient*, `thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
